{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd555848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "389721a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = T.device('cuda' if T.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08945224",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "from datasets.wcst import WCST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d2bc29",
   "metadata": {},
   "source": [
    "### 1. Dataset Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73743b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BATCHES_PER_CONTEXT = 20\n",
    "N_CONTEXT_SWITCHES = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47ffd5",
   "metadata": {},
   "source": [
    "### 2. Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "365835c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcst = WCST(BATCH_SIZE)\n",
    "data = []\n",
    "targets = []\n",
    "\n",
    "for i in range(N_CONTEXT_SWITCHES):\n",
    "    for j in range(BATCHES_PER_CONTEXT):\n",
    "        X, t = next(wcst.gen_batch())\n",
    "        for k in range(BATCH_SIZE):\n",
    "            data.append(X[k])\n",
    "            targets.append(t[k])\n",
    "    wcst.context_switch()\n",
    "\n",
    "data = T.tensor(np.array(data), dtype=T.long).to(device=device)\n",
    "targets = T.tensor(np.array(targets), dtype=T.long).to(device=device)\n",
    "dataset = TensorDataset(data, targets)\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(\n",
    "    dataset, [0.6, 0.2, 0.2]\n",
    ")\n",
    "\n",
    "train_dataset_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataset_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE)\n",
    "test_dataset_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f524267",
   "metadata": {},
   "source": [
    "## Transformer Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a8bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformer import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739c3fe",
   "metadata": {},
   "source": [
    "### 1. Transformer Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "606c1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = len(wcst.card_indices) + len(wcst.categories) + 2 # Cards + Categories + 'SEP' + 'EOS'\n",
    "EMBEDDING_SIZE = 32\n",
    "N_ATTENTION_HEADS = 4\n",
    "N_BLOCKS = 3\n",
    "MAX_SEQUENCE_LENGTH = 10\n",
    "FF_DIMS = 64\n",
    "DROPOUT_PROB = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab9fc96",
   "metadata": {},
   "source": [
    "### 2. Transformer Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f25ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    VOCABULARY_SIZE, VOCABULARY_SIZE, EMBEDDING_SIZE, N_ATTENTION_HEADS,\n",
    "    N_BLOCKS, MAX_SEQUENCE_LENGTH, FF_DIMS, DROPOUT_PROB, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7489333",
   "metadata": {},
   "source": [
    "## Training Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42f3ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5d23d",
   "metadata": {},
   "source": [
    "### 1. Train, Validate, Evaluate Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a8ee8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    train_loader: DataLoader, validation_loader: DataLoader, model: Transformer, criterion: nn.CrossEntropyLoss, \n",
    "    optimizer: optim.Optimizer, max_epochs: int = 20, device: str | T.device = \"cpu\", patience: int = 3\n",
    "    ):\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    train_losses, train_accs = [], []\n",
    "    test_losses, test_accs = [], []\n",
    "    best_model_state = model.state_dict()\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{max_epochs}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        epoch_train_losses = []\n",
    "        total_correct = 0\n",
    "        total_tokens = 0\n",
    "\n",
    "        for batch_idx, (X, target) in enumerate(train_loader):\n",
    "            encoder_input, target = X.to(device), target.to(device)\n",
    "\n",
    "            # Decoder inputs/targets (shifted)\n",
    "            decoder_input = target[:, :-1]\n",
    "            decoder_target = target[:, 1:].reshape(-1)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(encoder_input, decoder_input).reshape(-1, VOCABULARY_SIZE)\n",
    "            loss = criterion(logits, decoder_target)\n",
    "\n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accuracy\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == decoder_target).sum().item()\n",
    "            total_tokens += decoder_target.size(0)\n",
    "\n",
    "            epoch_train_losses.append(loss.item())\n",
    "\n",
    "            if batch_idx % 10 == 0 or batch_idx == len(train_loader) - 1:\n",
    "                print(f\"Train Batch {batch_idx+1}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "        train_loss = np.mean(epoch_train_losses)\n",
    "        train_acc = total_correct / total_tokens\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        test_batch_losses = []\n",
    "        test_correct = 0\n",
    "        test_tokens = 0\n",
    "\n",
    "        with T.no_grad():\n",
    "            for X, target in validation_loader:\n",
    "                encoder_input, target = X.to(device), target.to(device)\n",
    "                decoder_input = target[:, :-1]\n",
    "                decoder_target = target[:, 1:].reshape(-1)\n",
    "\n",
    "                logits = model(encoder_input, decoder_input).reshape(-1, VOCABULARY_SIZE)\n",
    "                loss = criterion(logits, decoder_target)\n",
    "\n",
    "                preds = logits.argmax(dim=1)\n",
    "                test_correct += (preds == decoder_target).sum().item()\n",
    "                test_tokens += decoder_target.size(0)\n",
    "\n",
    "                test_batch_losses.append(loss.item())\n",
    "\n",
    "        val_loss = np.mean(test_batch_losses)\n",
    "        val_acc = test_correct / test_tokens\n",
    "        test_losses.append(val_loss)\n",
    "        test_accs.append(val_acc)\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # --- Early Stopping ---\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"Validation loss improved — saving model (Loss: {val_loss:.4f})\")\n",
    "        # else:\n",
    "        #     patience_counter += 1\n",
    "        #     print(f\"No improvement ({patience_counter}/{patience})\")\n",
    "        #     if patience_counter >= patience:\n",
    "        #         print(\"\\nEarly stopping triggered. Restoring best model.\")\n",
    "        #         model.load_state_dict(best_model_state)\n",
    "        #         break\n",
    "\n",
    "    print(\"\\nTraining complete\")\n",
    "\n",
    "    return {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_accs\": train_accs,\n",
    "        \"test_losses\": test_losses,\n",
    "        \"test_accs\": test_accs,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44864dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_loader: DataLoader, model: Transformer, criterion: nn.CrossEntropyLoss, device: str | T.device = \"cpu\"):\n",
    "    test_losses, test_accs = [], []\n",
    "\n",
    "    model.eval()\n",
    "    test_batch_losses = []\n",
    "    test_correct = 0\n",
    "    test_tokens = 0\n",
    "\n",
    "    with T.no_grad():\n",
    "        for X, target in test_loader:\n",
    "            encoder_input, target = X.to(device), target.to(device)\n",
    "            decoder_input = target[:, :-1]\n",
    "            decoder_target = target[:, 1:].reshape(-1)\n",
    "\n",
    "            logits = model(encoder_input, decoder_input).reshape(-1, VOCABULARY_SIZE)\n",
    "            loss = criterion(logits, decoder_target)\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            test_correct += (preds == decoder_target).sum().item()\n",
    "            test_tokens += decoder_target.size(0)\n",
    "\n",
    "            test_batch_losses.append(loss.item())\n",
    "\n",
    "    test_loss = np.mean(test_batch_losses)\n",
    "    test_acc = test_correct / test_tokens\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    return {\n",
    "        \"test_losses\": test_losses,\n",
    "        \"test_accs\": test_accs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d863c67",
   "metadata": {},
   "source": [
    "### 2. Train Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59271964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "MAX_EPOCHS = 40\n",
    "LEARNING_RATE = 1e-3\n",
    "BETAS = (0.9, 0.98)\n",
    "EPSILON = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5c8f99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 4.5561\n",
      "Train Batch 11/12 | Loss: 2.6068\n",
      "Train Batch 12/12 | Loss: 2.4839\n",
      "[Epoch 1] Train Loss: 3.1554 | Train Acc: 0.3841\n",
      "[Epoch 1] Val Loss: 2.3408 | Val Acc: 0.5000\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 2.3408)\n",
      "\n",
      "Epoch 2/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 2.4952\n",
      "Train Batch 11/12 | Loss: 2.0983\n",
      "Train Batch 12/12 | Loss: 1.8487\n",
      "[Epoch 2] Train Loss: 2.1298 | Train Acc: 0.5000\n",
      "[Epoch 2] Val Loss: 1.8022 | Val Acc: 0.5000\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 1.8022)\n",
      "\n",
      "Epoch 3/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 1.7330\n",
      "Train Batch 11/12 | Loss: 1.5373\n",
      "Train Batch 12/12 | Loss: 1.5445\n",
      "[Epoch 3] Train Loss: 1.6106 | Train Acc: 0.5586\n",
      "[Epoch 3] Val Loss: 1.3652 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 1.3652)\n",
      "\n",
      "Epoch 4/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 1.4346\n",
      "Train Batch 11/12 | Loss: 1.2079\n",
      "Train Batch 12/12 | Loss: 1.1490\n",
      "[Epoch 4] Train Loss: 1.2777 | Train Acc: 0.6250\n",
      "[Epoch 4] Val Loss: 1.1158 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 1.1158)\n",
      "\n",
      "Epoch 5/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 1.1343\n",
      "Train Batch 11/12 | Loss: 1.0145\n",
      "Train Batch 12/12 | Loss: 1.0072\n",
      "[Epoch 5] Train Loss: 1.0793 | Train Acc: 0.6276\n",
      "[Epoch 5] Val Loss: 0.9857 | Val Acc: 0.5977\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.9857)\n",
      "\n",
      "Epoch 6/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.9843\n",
      "Train Batch 11/12 | Loss: 0.9417\n",
      "Train Batch 12/12 | Loss: 0.9148\n",
      "[Epoch 6] Train Loss: 0.9593 | Train Acc: 0.6328\n",
      "[Epoch 6] Val Loss: 0.8896 | Val Acc: 0.6445\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.8896)\n",
      "\n",
      "Epoch 7/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.9173\n",
      "Train Batch 11/12 | Loss: 0.8514\n",
      "Train Batch 12/12 | Loss: 0.8544\n",
      "[Epoch 7] Train Loss: 0.8807 | Train Acc: 0.6289\n",
      "[Epoch 7] Val Loss: 0.8329 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.8329)\n",
      "\n",
      "Epoch 8/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.8540\n",
      "Train Batch 11/12 | Loss: 0.8257\n",
      "Train Batch 12/12 | Loss: 0.8140\n",
      "[Epoch 8] Train Loss: 0.8312 | Train Acc: 0.6263\n",
      "[Epoch 8] Val Loss: 0.8043 | Val Acc: 0.6055\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.8043)\n",
      "\n",
      "Epoch 9/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.7915\n",
      "Train Batch 11/12 | Loss: 0.7718\n",
      "Train Batch 12/12 | Loss: 0.7935\n",
      "[Epoch 9] Train Loss: 0.7928 | Train Acc: 0.6523\n",
      "[Epoch 9] Val Loss: 0.7741 | Val Acc: 0.6523\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.7741)\n",
      "\n",
      "Epoch 10/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.7602\n",
      "Train Batch 11/12 | Loss: 0.7721\n",
      "Train Batch 12/12 | Loss: 0.7375\n",
      "[Epoch 10] Train Loss: 0.7686 | Train Acc: 0.6471\n",
      "[Epoch 10] Val Loss: 0.7637 | Val Acc: 0.6133\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.7637)\n",
      "\n",
      "Epoch 11/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.7551\n",
      "Train Batch 11/12 | Loss: 0.7486\n",
      "Train Batch 12/12 | Loss: 0.7441\n",
      "[Epoch 11] Train Loss: 0.7555 | Train Acc: 0.6354\n",
      "[Epoch 11] Val Loss: 0.7480 | Val Acc: 0.6016\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.7480)\n",
      "\n",
      "Epoch 12/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.7460\n",
      "Train Batch 11/12 | Loss: 0.7439\n",
      "Train Batch 12/12 | Loss: 0.7365\n",
      "[Epoch 12] Train Loss: 0.7434 | Train Acc: 0.6536\n",
      "[Epoch 12] Val Loss: 0.7403 | Val Acc: 0.6445\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.7403)\n",
      "\n",
      "Epoch 13/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.7340\n",
      "Train Batch 11/12 | Loss: 0.7082\n",
      "Train Batch 12/12 | Loss: 0.7294\n",
      "[Epoch 13] Train Loss: 0.7268 | Train Acc: 0.6523\n",
      "[Epoch 13] Val Loss: 0.7347 | Val Acc: 0.6133\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.7347)\n",
      "\n",
      "Epoch 14/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.6646\n",
      "Train Batch 11/12 | Loss: 0.7136\n",
      "Train Batch 12/12 | Loss: 0.7300\n",
      "[Epoch 14] Train Loss: 0.7073 | Train Acc: 0.6771\n",
      "[Epoch 14] Val Loss: 0.7245 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "Validation loss improved — saving model (Loss: 0.7245)\n",
      "\n",
      "Epoch 15/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.6984\n",
      "Train Batch 11/12 | Loss: 0.6790\n",
      "Train Batch 12/12 | Loss: 0.6771\n",
      "[Epoch 15] Train Loss: 0.6874 | Train Acc: 0.6901\n",
      "[Epoch 15] Val Loss: 0.7344 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 16/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.6281\n",
      "Train Batch 11/12 | Loss: 0.6596\n",
      "Train Batch 12/12 | Loss: 0.7103\n",
      "[Epoch 16] Train Loss: 0.6641 | Train Acc: 0.7057\n",
      "[Epoch 16] Val Loss: 0.7521 | Val Acc: 0.6523\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 17/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.6211\n",
      "Train Batch 11/12 | Loss: 0.6201\n",
      "Train Batch 12/12 | Loss: 0.5779\n",
      "[Epoch 17] Train Loss: 0.6464 | Train Acc: 0.7435\n",
      "[Epoch 17] Val Loss: 0.7599 | Val Acc: 0.6367\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 18/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.6530\n",
      "Train Batch 11/12 | Loss: 0.6318\n",
      "Train Batch 12/12 | Loss: 0.5855\n",
      "[Epoch 18] Train Loss: 0.6109 | Train Acc: 0.7474\n",
      "[Epoch 18] Val Loss: 0.7995 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 19/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.5830\n",
      "Train Batch 11/12 | Loss: 0.5823\n",
      "Train Batch 12/12 | Loss: 0.6497\n",
      "[Epoch 19] Train Loss: 0.6052 | Train Acc: 0.7552\n",
      "[Epoch 19] Val Loss: 0.8595 | Val Acc: 0.6211\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 20/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.5461\n",
      "Train Batch 11/12 | Loss: 0.6501\n",
      "Train Batch 12/12 | Loss: 0.5645\n",
      "[Epoch 20] Train Loss: 0.5934 | Train Acc: 0.7474\n",
      "[Epoch 20] Val Loss: 0.8082 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 21/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.5652\n",
      "Train Batch 11/12 | Loss: 0.5422\n",
      "Train Batch 12/12 | Loss: 0.5904\n",
      "[Epoch 21] Train Loss: 0.5842 | Train Acc: 0.7461\n",
      "[Epoch 21] Val Loss: 0.8091 | Val Acc: 0.6367\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 22/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.5664\n",
      "Train Batch 11/12 | Loss: 0.5075\n",
      "Train Batch 12/12 | Loss: 0.5744\n",
      "[Epoch 22] Train Loss: 0.5437 | Train Acc: 0.7721\n",
      "[Epoch 22] Val Loss: 0.8343 | Val Acc: 0.6445\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 23/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.4941\n",
      "Train Batch 11/12 | Loss: 0.4103\n",
      "Train Batch 12/12 | Loss: 0.4581\n",
      "[Epoch 23] Train Loss: 0.4896 | Train Acc: 0.8177\n",
      "[Epoch 23] Val Loss: 0.8912 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 24/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.5274\n",
      "Train Batch 11/12 | Loss: 0.5238\n",
      "Train Batch 12/12 | Loss: 0.5152\n",
      "[Epoch 24] Train Loss: 0.5010 | Train Acc: 0.7891\n",
      "[Epoch 24] Val Loss: 0.9019 | Val Acc: 0.6328\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 25/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.4765\n",
      "Train Batch 11/12 | Loss: 0.4188\n",
      "Train Batch 12/12 | Loss: 0.4080\n",
      "[Epoch 25] Train Loss: 0.4812 | Train Acc: 0.8060\n",
      "[Epoch 25] Val Loss: 0.9182 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 26/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.4754\n",
      "Train Batch 11/12 | Loss: 0.4204\n",
      "Train Batch 12/12 | Loss: 0.4046\n",
      "[Epoch 26] Train Loss: 0.4492 | Train Acc: 0.8229\n",
      "[Epoch 26] Val Loss: 0.9371 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 27/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.4516\n",
      "Train Batch 11/12 | Loss: 0.3408\n",
      "Train Batch 12/12 | Loss: 0.5421\n",
      "[Epoch 27] Train Loss: 0.4128 | Train Acc: 0.8424\n",
      "[Epoch 27] Val Loss: 1.0292 | Val Acc: 0.6406\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 28/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.4711\n",
      "Train Batch 11/12 | Loss: 0.5391\n",
      "Train Batch 12/12 | Loss: 0.4991\n",
      "[Epoch 28] Train Loss: 0.4073 | Train Acc: 0.8490\n",
      "[Epoch 28] Val Loss: 1.0082 | Val Acc: 0.6484\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 29/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.4454\n",
      "Train Batch 11/12 | Loss: 0.3687\n",
      "Train Batch 12/12 | Loss: 0.3154\n",
      "[Epoch 29] Train Loss: 0.4030 | Train Acc: 0.8542\n",
      "[Epoch 29] Val Loss: 1.0168 | Val Acc: 0.6406\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 30/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.3275\n",
      "Train Batch 11/12 | Loss: 0.5117\n",
      "Train Batch 12/12 | Loss: 0.3849\n",
      "[Epoch 30] Train Loss: 0.3792 | Train Acc: 0.8646\n",
      "[Epoch 30] Val Loss: 1.0458 | Val Acc: 0.6367\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 31/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.4579\n",
      "Train Batch 11/12 | Loss: 0.3927\n",
      "Train Batch 12/12 | Loss: 0.3633\n",
      "[Epoch 31] Train Loss: 0.3585 | Train Acc: 0.8568\n",
      "[Epoch 31] Val Loss: 1.1034 | Val Acc: 0.6367\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 32/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.2974\n",
      "Train Batch 11/12 | Loss: 0.4164\n",
      "Train Batch 12/12 | Loss: 0.3353\n",
      "[Epoch 32] Train Loss: 0.3438 | Train Acc: 0.8698\n",
      "[Epoch 32] Val Loss: 1.1072 | Val Acc: 0.6445\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 33/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.3668\n",
      "Train Batch 11/12 | Loss: 0.2350\n",
      "Train Batch 12/12 | Loss: 0.2960\n",
      "[Epoch 33] Train Loss: 0.3169 | Train Acc: 0.8828\n",
      "[Epoch 33] Val Loss: 1.1728 | Val Acc: 0.6406\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 34/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.2971\n",
      "Train Batch 11/12 | Loss: 0.3338\n",
      "Train Batch 12/12 | Loss: 0.3191\n",
      "[Epoch 34] Train Loss: 0.2997 | Train Acc: 0.8906\n",
      "[Epoch 34] Val Loss: 1.1979 | Val Acc: 0.6523\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 35/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.2629\n",
      "Train Batch 11/12 | Loss: 0.3986\n",
      "Train Batch 12/12 | Loss: 0.3035\n",
      "[Epoch 35] Train Loss: 0.2928 | Train Acc: 0.8776\n",
      "[Epoch 35] Val Loss: 1.1980 | Val Acc: 0.6445\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 36/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.2932\n",
      "Train Batch 11/12 | Loss: 0.2789\n",
      "Train Batch 12/12 | Loss: 0.1579\n",
      "[Epoch 36] Train Loss: 0.2393 | Train Acc: 0.9193\n",
      "[Epoch 36] Val Loss: 1.2895 | Val Acc: 0.6445\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 37/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.1491\n",
      "Train Batch 11/12 | Loss: 0.3246\n",
      "Train Batch 12/12 | Loss: 0.2836\n",
      "[Epoch 37] Train Loss: 0.2460 | Train Acc: 0.9115\n",
      "[Epoch 37] Val Loss: 1.2932 | Val Acc: 0.6523\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 38/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.3645\n",
      "Train Batch 11/12 | Loss: 0.2098\n",
      "Train Batch 12/12 | Loss: 0.2904\n",
      "[Epoch 38] Train Loss: 0.2222 | Train Acc: 0.9232\n",
      "[Epoch 38] Val Loss: 1.4054 | Val Acc: 0.6406\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 39/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.1813\n",
      "Train Batch 11/12 | Loss: 0.2536\n",
      "Train Batch 12/12 | Loss: 0.2981\n",
      "[Epoch 39] Train Loss: 0.2184 | Train Acc: 0.9193\n",
      "[Epoch 39] Val Loss: 1.4069 | Val Acc: 0.6367\n",
      "----------------------------------------\n",
      "\n",
      "Epoch 40/40\n",
      "----------------------------------------\n",
      "Train Batch 1/12 | Loss: 0.1642\n",
      "Train Batch 11/12 | Loss: 0.2250\n",
      "Train Batch 12/12 | Loss: 0.2675\n",
      "[Epoch 40] Train Loss: 0.2248 | Train Acc: 0.9167\n",
      "[Epoch 40] Val Loss: 1.4179 | Val Acc: 0.6367\n",
      "----------------------------------------\n",
      "\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "criterion =  nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=LEARNING_RATE, betas=BETAS, eps=EPSILON)\n",
    "\n",
    "results = train_model(\n",
    "    train_dataset_loader, validation_dataset_loader, transformer, criterion, \n",
    "    optimizer, max_epochs=MAX_EPOCHS, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917a1fa4",
   "metadata": {},
   "source": [
    "### 3. Test Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d144441",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_model(test_dataset_loader, transformer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28dac7b",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b590910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model: Transformer, source_sequence, start_tokens):\n",
    "    model.eval()\n",
    "    generated = start_tokens\n",
    "    \n",
    "    with T.no_grad():\n",
    "        logits = model(source_sequence, generated)\n",
    "    \n",
    "    # Greedy Selection\n",
    "    next_token = T.argmax(logits[:, -1, :], dim=-1, keepdim=True)\n",
    "\n",
    "    generated = T.cat([generated, next_token], dim=1)\n",
    "\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f458678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Actual Trials\n",
      "[array(['blue', 'star', '1'], dtype='<U6'), array(['yellow', 'star', '3'], dtype='<U6'), array(['green', 'star', '2'], dtype='<U6'), array(['red', 'square', '4'], dtype='<U6'), array(['red', 'square', '3'], dtype='<U6'), 'SEP', 'C2', 'EOS', array(['blue', 'star', '4'], dtype='<U6'), 'SEP', 'C4']\n",
      "[array(['blue', 'square', '1'], dtype='<U6'), array(['blue', 'circle', '3'], dtype='<U6'), array(['blue', 'star', '2'], dtype='<U6'), array(['blue', 'star', '4'], dtype='<U6'), array(['green', 'star', '2'], dtype='<U6'), 'SEP', 'C3', 'EOS', array(['green', 'cross', '1'], dtype='<U6'), 'SEP', 'C1']\n",
      "[array(['yellow', 'star', '4'], dtype='<U6'), array(['blue', 'star', '2'], dtype='<U6'), array(['blue', 'square', '3'], dtype='<U6'), array(['blue', 'circle', '1'], dtype='<U6'), array(['red', 'cross', '3'], dtype='<U6'), 'SEP', 'C3', 'EOS', array(['yellow', 'cross', '3'], dtype='<U6'), 'SEP', 'C3']\n",
      "[array(['yellow', 'cross', '4'], dtype='<U6'), array(['red', 'cross', '2'], dtype='<U6'), array(['green', 'square', '1'], dtype='<U6'), array(['red', 'circle', '3'], dtype='<U6'), array(['yellow', 'star', '1'], dtype='<U6'), 'SEP', 'C3', 'EOS', array(['green', 'star', '1'], dtype='<U6'), 'SEP', 'C3']\n",
      "[array(['green', 'cross', '2'], dtype='<U6'), array(['blue', 'star', '4'], dtype='<U6'), array(['green', 'square', '3'], dtype='<U6'), array(['green', 'square', '1'], dtype='<U6'), array(['green', 'square', '4'], dtype='<U6'), 'SEP', 'C2', 'EOS', array(['yellow', 'circle', '4'], dtype='<U6'), 'SEP', 'C2']\n",
      "Feature for Classification:  1 \n",
      "\n",
      "# Predicted Trials\n",
      "[array(['red', 'circle', '2'], dtype='<U6'), array(['red', 'star', '4'], dtype='<U6'), array(['green', 'square', '3'], dtype='<U6'), array(['green', 'cross', '1'], dtype='<U6'), array(['green', 'circle', '2'], dtype='<U6'), 'SEP', 'C1', 'EOS', array(['red', 'star', '2'], dtype='<U6'), 'SEP', 'C1']\n",
      "[array(['blue', 'circle', '1'], dtype='<U6'), array(['blue', 'circle', '3'], dtype='<U6'), array(['blue', 'square', '2'], dtype='<U6'), array(['yellow', 'cross', '4'], dtype='<U6'), array(['blue', 'star', '1'], dtype='<U6'), 'SEP', 'C1', 'EOS', array(['red', 'star', '2'], dtype='<U6'), 'SEP', 'C3']\n",
      "[array(['red', 'star', '3'], dtype='<U6'), array(['yellow', 'square', '2'], dtype='<U6'), array(['green', 'square', '4'], dtype='<U6'), array(['green', 'cross', '1'], dtype='<U6'), array(['yellow', 'square', '3'], dtype='<U6'), 'SEP', 'C1', 'EOS', array(['green', 'star', '4'], dtype='<U6'), 'SEP', 'C3']\n",
      "[array(['red', 'star', '3'], dtype='<U6'), array(['blue', 'circle', '2'], dtype='<U6'), array(['blue', 'star', '4'], dtype='<U6'), array(['blue', 'square', '1'], dtype='<U6'), array(['red', 'cross', '3'], dtype='<U6'), 'SEP', 'C1', 'EOS', array(['red', 'cross', '2'], dtype='<U6'), 'SEP', 'C2']\n",
      "[array(['red', 'star', '2'], dtype='<U6'), array(['green', 'circle', '3'], dtype='<U6'), array(['yellow', 'circle', '4'], dtype='<U6'), array(['yellow', 'circle', '1'], dtype='<U6'), array(['blue', 'star', '1'], dtype='<U6'), 'SEP', 'C4', 'EOS', array(['blue', 'square', '2'], dtype='<U6'), 'SEP', 'C1']\n",
      "Feature for Classification:  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, target = train_dataset[:5]\n",
    "prediction = model_inference(transformer, x, target[:, : -1])\n",
    "\n",
    "print(\"# Actual Trials\")\n",
    "test_batch = [np.asarray(item.cpu()) for item in test_dataset[:5]]\n",
    "output = wcst.visualise_batch(test_batch)\n",
    "\n",
    "print(\"# Predicted Trials\")\n",
    "prediction_batch = [np.asarray(item.cpu()) for item in [x, prediction]]\n",
    "output = wcst.visualise_batch(prediction_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57522b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npl_project_2025 (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
